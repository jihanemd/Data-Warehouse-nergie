# ğŸš€ Data Warehouse Ã‰nergie France

**Pipeline ETL avec Apache Spark - Architecture Bronze/Silver/Gold**

Projet complet de Data Warehouse pour l'analyse des donnÃ©es d'Ã©nergie en France, implÃ©mentant une architecture moderne de data lakehouse avec Spark et Parquet.

---

## ğŸ“‹ Table des matiÃ¨res

- [ğŸ¯ AperÃ§u](#-aperÃ§u)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ“¦ Installation](#-installation)
- [ğŸš€ DÃ©marrage rapide](#-dÃ©marrage-rapide)
- [ğŸ“‚ Structure du projet](#-structure-du-projet)
- [ğŸ”§ Configuration](#-configuration)
- [ğŸ“Š DonnÃ©es sources](#-donnÃ©es-sources)
- [ğŸ¯ Utilisation](#-utilisation)
- [ğŸ’¾ Star Schema](#-star-schema)
- [ğŸ“ˆ RequÃªtes BI](#-requÃªtes-bi)
- [ğŸ› ï¸ Troubleshooting](#ï¸-troubleshooting)
- [ğŸ“ Licence](#-licence)

---

## ğŸ¯ AperÃ§u

Ce projet implÃ©mente un **pipeline ETL complet** pour ingÃ©rer, nettoyer et transformer des donnÃ©es d'Ã©nergie franÃ§aises en un data warehouse **prÃªt pour Business Intelligence**.

### âœ¨ CaractÃ©ristiques principales

- âœ… **3 couches de donnÃ©es** : Bronze (RAW) â†’ Silver (CLEAN) â†’ Gold (ANALYTICS)
- âœ… **Data Quality** : Validation automatique avec rejet des records invalides
- âœ… **Star Schema Enrichi** : 4 dimensions + 3 fact tables pour analyses multi-niveaux
- âœ… **Format Parquet** : Compression, columnar storage, compatible avec tous les outils BI
- âœ… **Orchestration** : Script Python avec modes d'exÃ©cution flexibles
- âœ… **Performance** : Traitement de 61k+ lignes en ~7 secondes
- âœ… **Dimension gÃ©ographique** : 31 rÃ©gions franÃ§aises (NUTS codes)
- âœ… **Master data ENR** : 9,744 installations avec mÃ©tadonnÃ©es (technologie, capacitÃ©, localisation)

### ğŸ“Š DonnÃ©es couvertes

| Source | Lignes | Description |
|--------|--------|-------------|
| **france_time_series.csv** | 50,393 | SÃ©ries chronologiques horaires de production |
| **eurostat_electricity_france.csv** | 417 | DonnÃ©es Eurostat Ã©lectricitÃ© |
| **time_series_60min_sample.csv** | 1,000 | Ã‰chantillon haute frÃ©quence (60min) |
| **renewable_power_plants_FR.csv** | 9,744 | Registre des installations ENR |
| **TOTAL** | **61,554** | DonnÃ©es prÃªtes pour analyse |

---

## ğŸ—ï¸ Architecture

### Flux de donnÃ©es

```
Data Sources (CSV)
      â†“
   BRONZE LAYER (Raw Ingestion)
      â€¢ Lecture CSV directe
      â€¢ Ajout colonnes systÃ¨me (_source_file, _ingest_ts, _ingest_date)
      â€¢ Format Parquet sans transformation
      â€¢ 61,554 lignes
      â†“
   SILVER LAYER (Data Quality & Cleaning)
      â€¢ Type casting (string â†’ numeric/date)
      â€¢ Validation mÃ©tier (pas de valeurs nÃ©gatives)
      â€¢ Deduplication
      â€¢ Timestamp validation
      â€¢ Rejet des records invalides
      â€¢ 61,554 lignes valides (100% acceptance)
      â†“
   GOLD LAYER (Star Schema Enrichi - 7 Tables)
      â€¢ 4 Dimensions: dim_date, dim_energy_type, dim_location, dim_plant
      â€¢ 3 Fact Tables: fact_energy_production, fact_renewable_capacity, fact_monthly_summary
      â†“
   BI TOOLS (Power BI, Tableau, Metabase, etc.)
```

### SchÃ©ma en Ã©toile enrichi (Star Schema)

```
                    â”Œâ”€ dim_date â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ (4,383 rows)       â”‚
                    â”‚ â€¢ date_id          â”‚
                    â”‚ â€¢ date, year, etc. â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†‘
                          â”‚ FK
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ fact_energy_production â”‚
              â”‚     (6,301 rows)       â”‚
              â”‚ â€¢ date_id (FK)         â”‚
              â”‚ â€¢ energy_type_id (FK)  â”‚
              â”‚ â€¢ value_mw, avg_mw     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ FK
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ dim_energy_type  â”‚
                    â”‚  (5 rows)        â”‚
                    â”‚ â€¢ energy_type_id â”‚
                    â”‚ â€¢ Solar, Wind    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ fact_renewable_capacity      â”‚
              â”‚     (24 rows)                â”‚
              â”‚ â€¢ region (FK)                â”‚
              â”‚ â€¢ energy_type_id (FK)        â”‚
              â”‚ â€¢ total_capacity_mw          â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ FK         â”‚ FK
              â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚dim_location  â”‚ dim_plant     â”‚
              â”‚  (31 rows)   â”‚ (9,744 rows)  â”‚
              â”‚â€¢ region_name â”‚ â€¢ plant_name  â”‚
              â”‚â€¢ region_code â”‚ â€¢ technology  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚fact_monthly_summary    â”‚
              â”‚     (x rows)           â”‚
              â”‚ â€¢ date_id (FK)         â”‚
              â”‚ â€¢ energy_type_id (FK)  â”‚
              â”‚ â€¢ production_mwh       â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Installation

### PrÃ©requis

- **Python 3.11+** (testÃ© avec 3.11)
- **Windows/Linux/Mac**
- **~2 GB** d'espace disque (donnÃ©es + venv)

### 1. Cloner le projet

```bash
git clone <repository>
cd Spark_dataSpace_Projet
```

### 2. CrÃ©er l'environnement virtuel

```bash
# Windows
python -m venv venv_spark
.\venv_spark\Scripts\Activate.ps1

# Linux/Mac
python3 -m venv venv_spark
source venv_spark/bin/activate
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 4. VÃ©rifier l'installation

```bash
python -c "import pandas, pyspark, pyarrow; print('âœ… Installation OK')"
```

---

## ğŸš€ DÃ©marrage rapide

### ExÃ©cution du pipeline complet

```bash
# Run.py utilise auto-dÃ©tection du Python venv
python run.py

# Ou avec le Python du venv explicite
.\venv_spark\Scripts\python.exe run.py
```

**RÃ©sultat attendu:**
```
ğŸš€ PIPELINE ETL - Data Warehouse Ã‰nergie France
ğŸ“‚ Projet: c:\...\Spark_dataSpace_Projet
ğŸ Python: .\venv_spark\Scripts\python.exe

ğŸ“‹ Ã‰TAPES: BRONZE â†’ SILVER â†’ GOLD

âœ… ğŸŸ¤ BRONZE (Ingestion RAW) - SUCCÃˆS
âœ… âšª SILVER (Nettoyage) - SUCCÃˆS
âœ… ğŸŸ¡ GOLD (Star Schema) - SUCCÃˆS

ğŸ“Š RÃ‰SUMÃ‰ FINAL
   â€¢ Ã‰tapes rÃ©ussies: 3/3
   â€¢ DurÃ©e totale: 7.2s
   â€¢ Fichiers Parquet: 11
```

### Modes d'exÃ©cution

```bash
# Mode 1: Pipeline complet (par dÃ©faut)
python run.py
# ExÃ©cute: BRONZE â†’ SILVER â†’ GOLD

# Mode 2: Seulement BRONZE
python run.py --bronze
# ExÃ©cute: BRONZE uniquement

# Mode 3: BRONZE + SILVER
python run.py --silver
# ExÃ©cute: BRONZE â†’ SILVER

# Mode 4: Nettoyer + relancer
python run.py --clean
# Supprime data/warehouse puis exÃ©cute BRONZE â†’ SILVER â†’ GOLD

# Mode 5: Nettoyer + BRONZE
python run.py --clean --bronze
# Supprime data/warehouse puis exÃ©cute BRONZE uniquement
```

---

## ğŸ“‚ Structure du projet

```
Spark_dataSpace_Projet/
â”‚
â”œâ”€â”€ README.md                          â† Ce fichier
â”œâ”€â”€ requirements.txt                   â† DÃ©pendances Python
â”œâ”€â”€ run.py                             â† Orchestrateur principal
â”‚
â”œâ”€â”€ conf/
â”‚   â””â”€â”€ config.yaml                    â† Configuration centralisÃ©e
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ jobs/                          â† Pipeline ETL
â”‚   â”‚   â”œâ”€â”€ 01_bronze_ingest_pandas.py      (Ingestion RAW)
â”‚   â”‚   â”œâ”€â”€ 02_silver_clean.py              (Nettoyage & DQ)
â”‚   â”‚   â””â”€â”€ 03_gold_dwh.py                  (Star Schema)
â”‚   â”‚
â”‚   â””â”€â”€ lib/                           â† Librairies communes
â”‚       â”œâ”€â”€ spark_utils.py             (Utilitaires Spark)
â”‚       â””â”€â”€ dq_utils.py                (Data Quality)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ landing/                       â† Fichiers CSV sources
â”‚   â”‚   â”œâ”€â”€ france_time_series.csv
â”‚   â”‚   â”œâ”€â”€ eurostat_electricity_france.csv
â”‚   â”‚   â”œâ”€â”€ time_series_60min_sample.csv
â”‚   â”‚   â””â”€â”€ renewable_power_plants_FR.csv
â”‚   â”‚
â”‚   â””â”€â”€ warehouse/                     â† Data Warehouse
â”‚       â”œâ”€â”€ bronze/                    â† Raw data (Parquet)
â”‚       â”‚   â”œâ”€â”€ france_time_series/
â”‚       â”‚   â”œâ”€â”€ eurostat_electricity_france/
â”‚       â”‚   â”œâ”€â”€ time_series_60min_sample/
â”‚       â”‚   â””â”€â”€ renewable_power_plants_FR/
â”‚       â”‚
â”‚       â”œâ”€â”€ silver/                    â† Cleaned data (Parquet)
â”‚       â”‚   â”œâ”€â”€ france_time_series/
â”‚       â”‚   â”œâ”€â”€ eurostat_electricity_france/
â”‚       â”‚   â”œâ”€â”€ time_series_60min/
â”‚       â”‚   â””â”€â”€ renewable_plants/
â”‚       â”‚
â”‚       â”œâ”€â”€ gold/                      â† Analytics (Star Schema Enrichi)
â”‚       â”‚   â”œâ”€â”€ dim_date/               â† 4,383 dates (2015-2026)
â”‚       â”‚   â”œâ”€â”€ dim_energy_type/        â† 5 types d'Ã©nergie
â”‚       â”‚   â”œâ”€â”€ dim_location/           â† 31 rÃ©gions franÃ§aises
â”‚       â”‚   â”œâ”€â”€ dim_plant/              â† 9,744 installations ENR
â”‚       â”‚   â”œâ”€â”€ fact_energy_production/ â† 6,301 records d'agrÃ©gation journaliÃ¨re
â”‚       â”‚   â”œâ”€â”€ fact_renewable_capacity/â† 24 records capacitÃ© par rÃ©gion/tech
â”‚       â”‚   â””â”€â”€ fact_monthly_summary/   â† RÃ©sumÃ©s mensuels consolidÃ©s
â”‚       â”‚
â”‚       â””â”€â”€ dq/                        â† Rejected records
â”‚           â”œâ”€â”€ france_time_series_rejects/
â”‚           â”œâ”€â”€ eurostat_rejects/
â”‚           â”œâ”€â”€ time_series_rejects/
â”‚           â””â”€â”€ renewable_rejects/
â”‚
â””â”€â”€ venv_spark/                        â† Environnement Python (auto-crÃ©Ã©)
    â”œâ”€â”€ lib/site-packages/
    â”œâ”€â”€ Scripts/ (Windows) / bin/ (Linux)
    â””â”€â”€ pyvenv.cfg
```

---

## ğŸ”§ Configuration

### Fichier: `conf/config.yaml`

```yaml
# Chemins de donnÃ©es
paths:
  landing: "data/landing"
  warehouse: "data/warehouse"
  bronze: "data/warehouse/bronze"
  silver: "data/warehouse/silver"
  gold: "data/warehouse/gold"
  dq: "data/warehouse/dq"

# Sources CSV
sources:
  france_time_series:
    path: "data/landing/france_time_series.csv"
    delimiter: ","
    header: true
    
  eurostat_electricity_france:
    path: "data/landing/eurostat_electricity_france.csv"
    delimiter: ","
    header: true

# ParamÃ¨tres Spark
spark:
  app_name: "DataWarehouse_Energie_France"
  master: "local[*]"
  adaptive_execution: true
  shuffle_partitions: 4
  memory: "2g"
  cores: "4"
```

Modifiez ce fichier pour adapter les chemins, dÃ©limiteurs ou paramÃ¨tres Spark Ã  votre environnement.

---

## ğŸ“Š DonnÃ©es sources

### 1. france_time_series.csv

**Production Ã©lectrique horaire 2015-2026**

```
DateTime,Load,Solar,Wind Onshore,Wind Offshore,Hydro,Thermal,Pumping
2015-01-01T00:00:00+0100,52620,0,1380,0,7560,27400,-1500
2015-01-01T01:00:00+0100,50850,0,1286,0,7480,26900,-1500
...
```

**Colonnes** : DateTime, Load, Solar, Wind Onshore, Wind Offshore, Hydro, Thermal, Pumping  
**Lignes** : 50,393  
**PÃ©riode** : 2015-2026  

---

### 2. eurostat_electricity_france.csv

**DonnÃ©es officielles Eurostat**

```
Year,Month,Renewable_Production,Total_Production,Renewable_Percentage
2015,01,4500,45000,10.0
2015,02,4800,46000,10.4
...
```

**Colonnes** : Year, Month, Renewable_Production, Total_Production, Renewable_Percentage  
**Lignes** : 417  

---

### 3. time_series_60min_sample.csv

**Ã‰chantillon haute frÃ©quence**

```
timestamp,value_mw,source
2015-01-01 01:00:00,5726.0,Load
2015-01-01 02:00:00,6593.0,Load
...
```

**Colonnes** : timestamp, value_mw, source  
**Lignes** : 1,000  

---

### 4. renewable_power_plants_FR.csv

**Registre des installations ENR (Open Data RÃ©seaux Ã‰nergies)**

```
electrical_capacity,energy_source_level_1,technology,lat,lon,...
0.1,Renewable,Photovoltaics,48.69,7.78,...
2.2,Renewable,Hydro,45.15,5.72,...
...
```

**Colonnes** : 30 (electrical_capacity, technology, location, status, etc.)  
**Lignes** : 9,744  

---

## ğŸ¯ Utilisation

### ExÃ©cuter une seule couche

```bash
# IngÃ©rer les donnÃ©es brutes uniquement
python run.py --bronze

# Nettoyer et valider les donnÃ©es
python run.py --silver

# CrÃ©er le data warehouse analytique
python run.py --gold
```

### Relancer le pipeline

```bash
# Supprimer toutes les donnÃ©es et recommencer
python run.py --clean

# Supprimer et relancer seulement BRONZE
python run.py --clean --bronze
```

### ExÃ©cuter un job spÃ©cifique

```bash
# Job Bronze seul
.\venv_spark\Scripts\python.exe src/jobs/01_bronze_ingest_pandas.py

# Job Silver seul
.\venv_spark\Scripts\python.exe src/jobs/02_silver_clean.py

# Job Gold seul
.\venv_spark\Scripts\python.exe src/jobs/03_gold_dwh.py
```

---

## ğŸ’¾ Star Schema

### Dimension: dim_date

**Couverture:** 2015-01-01 Ã  2026-12-31 (4,383 dates)

```sql
SELECT * FROM gold.dim_date LIMIT 5;

date_id       date  year  month  day  quarter  week_of_year  day_of_week  day_name    is_weekend  is_holiday
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
20150101      2015-01-01  2015  1     1        1             1            3          Thursday     0          1
20150102      2015-01-02  2015  1     2        1             1            4          Friday       0          0
20150103      2015-01-03  2015  1     3        1             1            5          Saturday     1          0
20150104      2015-01-04  2015  1     4        1             1            6          Sunday       1          0
20150105      2015-01-05  2015  1     5        1             2            1          Monday       0          0
```

### Dimension: dim_energy_type

**5 catÃ©gories d'Ã©nergie**

```sql
SELECT * FROM gold.dim_energy_type;

energy_type_id  energy_type_name    description                      unit  category
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1               Solar               Solar photovoltaic generation     MW    Renewable
2               Wind Onshore        Wind onshore generation           MW    Renewable
3               Load (Consumption)  Electrical load / consumption     MW    Consumption
4               Hydro               Hydroelectric generation          MW    Renewable
5               Other               Other renewable/thermal sources   MW    Other
```

### Dimension: dim_location

**31 rÃ©gions franÃ§aises avec codes NUTS**

```sql
SELECT * FROM gold.dim_location LIMIT 5;

location_id  nuts_1_code  nuts_2_code  region_name           region_code  country
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1            FRF          FRF1         Grand-Est             44           FR
2            FRF          FRF1         Alsace                42           FR
3            FRK          FRK2         Auvergne-RhÃ´ne-Alpes  84           FR
4            FRK          FRK2         IsÃ¨re                 38           FR
5            FRL          FRL1         Ãle-de-France         75           FR
```

### Dimension: dim_plant

**9,744 installations ENR avec caractÃ©ristiques**

```sql
SELECT * FROM gold.dim_plant LIMIT 3;

plant_id  plant_name             technology      energy_source     capacity_mw  latitude   longitude   commissioning_date  region
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1         SABLIERE ENERGIE       Photovoltaics   Renewable energy  0.1          48.69      7.78        2015-01-03          Grand-Est
2         CENTRALE DU RONDEAU    Hydro           Renewable energy  2.2          45.15      5.72        2015-01-03          Auvergne-RhÃ´ne-Alpes
3         Unknown                Photovoltaics   Renewable energy  0.0828       46.14      2.35        2015-01-04          Nouvelle-Aquitaine
```

### Fact Table: fact_energy_production

**6,301 enregistrements d'agrÃ©gation journaliÃ¨re**

```sql
SELECT * FROM gold.fact_energy_production 
WHERE date_id = 20150101 
LIMIT 3;

date_id  energy_type_id  country  value_mw   value_min_mw  value_max_mw  value_avg_mw  nb_records
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
20150101 3               FR       1521956.0  60798.0       71682.0       66172.0       23
20150102 3               FR       1637422.0  60686.0       73971.0       68225.9       24
20150103 3               FR       1510660.0  57700.0       68498.0       62944.1       24
```

### Fact Table: fact_renewable_capacity

**24 enregistrements de capacitÃ© installÃ©e par rÃ©gion et type**

```sql
SELECT * FROM gold.fact_renewable_capacity 
ORDER BY total_capacity_mw DESC 
LIMIT 3;

date_id    energy_type_id  region               total_capacity_mw  avg_capacity_mw  nb_plants
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
20260111   1               Nouvelle-Aquitaine  1250.5             0.45             2781
20260111   1               Auvergne-RhÃ´ne-Alpes 890.2             0.38             2340
20260111   2               Hauts-de-France     1650.8             2.15             765
```

### Fact Table: fact_monthly_summary

**RÃ©sumÃ©s mensuels consolidÃ©s pour requÃªtes BI rapides**

```sql
SELECT * FROM gold.fact_monthly_summary 
WHERE date_id >= 20260101 
LIMIT 3;

date_id    energy_type_id  country  production_mwh  avg_mw  min_mw  max_mw  nb_records
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
20260101   3               FR       37259812.0      51388   45690   62145   744
20260101   1               FR       2156400.5       2984    125     8945    744
20260101   2               FR       4128750.2       5716    450     12350   744
```

---

## ğŸ“ˆ RequÃªtes BI

### RequÃªte 1: CapacitÃ© ENR par rÃ©gion et technologie

```sql
SELECT 
    l.region_name,
    l.region_code,
    e.energy_type_name,
    ROUND(f.total_capacity_mw, 2) as total_capacity_mw,
    ROUND(f.avg_capacity_mw, 4) as avg_capacity_per_plant,
    f.nb_plants,
    RANK() OVER (PARTITION BY e.energy_type_id ORDER BY f.total_capacity_mw DESC) as rank_by_energy_type
FROM gold.fact_renewable_capacity f
JOIN gold.dim_location l ON f.region = l.region_name
JOIN gold.dim_energy_type e ON f.energy_type_id = e.energy_type_id
WHERE f.date_id = 20260111
ORDER BY total_capacity_mw DESC;
```

### RequÃªte 2: Production journaliÃ¨re par type d'Ã©nergie

```sql
SELECT 
    d.date,
    d.day_name,
    e.energy_type_name,
    ROUND(f.value_avg_mw, 2) as avg_production_mw,
    ROUND(f.value_min_mw, 2) as min_production_mw,
    ROUND(f.value_max_mw, 2) as max_production_mw,
    f.nb_records as nb_hourly_records,
    ROUND(100 * f.value_avg_mw / (SUM(f.value_avg_mw) OVER (PARTITION BY f.date_id)), 2) as pct_of_total
FROM gold.fact_energy_production f
JOIN gold.dim_date d ON f.date_id = d.date_id
JOIN gold.dim_energy_type e ON f.energy_type_id = e.energy_type_id
WHERE d.year = 2026 AND f.country = 'FR'
ORDER BY d.date DESC, e.energy_type_name;
```

### RequÃªte 3: Installations ENR par rÃ©gion et technologie

```sql
SELECT 
    l.region_name,
    p.technology,
    COUNT(*) as nb_installations,
    ROUND(SUM(p.capacity_mw), 2) as total_capacity_mw,
    ROUND(AVG(p.capacity_mw), 4) as avg_capacity_mw,
    MIN(p.commissioning_date) as first_commissioning,
    MAX(p.commissioning_date) as last_commissioning,
    COUNT(DISTINCT YEAR(p.commissioning_date)) as years_of_deployment
FROM gold.dim_plant p
JOIN gold.dim_location l ON p.region = l.region_name
WHERE p.commissioning_date <= CURRENT_DATE
GROUP BY l.region_name, p.technology
ORDER BY total_capacity_mw DESC;
```

### RequÃªte 4: RÃ©sumÃ© mensuel production vs consommation

```sql
SELECT 
    d.date,
    d.year,
    d.month,
    SUM(CASE WHEN e.energy_type_id = 3 THEN f.production_mwh ELSE 0 END) as consumption_mwh,
    SUM(CASE WHEN e.energy_type_id IN (1, 2, 4) THEN f.production_mwh ELSE 0 END) as renewable_production_mwh,
    ROUND(100 * SUM(CASE WHEN e.energy_type_id IN (1, 2, 4) THEN f.production_mwh ELSE 0 END)
          / SUM(CASE WHEN e.energy_type_id = 3 THEN f.production_mwh ELSE 0 END), 2) as renewable_percentage
FROM gold.fact_monthly_summary f
JOIN gold.dim_date d ON f.date_id = d.date_id
JOIN gold.dim_energy_type e ON f.energy_type_id = e.energy_type_id
WHERE f.country = 'FR'
GROUP BY d.date, d.year, d.month
ORDER BY d.year DESC, d.month DESC;
```

---

## ğŸ”Œ Connexion BI

### Power BI

1. **Obtenir les donnÃ©es** â†’ **Parquet**
2. Pointer vers `data/warehouse/gold/`
3. Charger les 7 tables:
   - Dimensions: `dim_date`, `dim_energy_type`, `dim_location`, `dim_plant`
   - Facts: `fact_energy_production`, `fact_renewable_capacity`, `fact_monthly_summary`
4. CrÃ©er relations dans Power Query:
   - `fact_energy_production.date_id` â†’ `dim_date.date_id`
   - `fact_energy_production.energy_type_id` â†’ `dim_energy_type.energy_type_id`
   - `fact_renewable_capacity.region` â†’ `dim_location.region_name`
   - `fact_renewable_capacity.energy_type_id` â†’ `dim_energy_type.energy_type_id`
   - `dim_plant.region` â†’ `dim_location.region_name`
5. CrÃ©er rapports avec DAX sur fact tables

### Tableau

1. **Connect** â†’ **Parquet**
2. SÃ©lectionner `data/warehouse/gold/fact_energy_production/`
3. Ajouter les dimensions via relationship panel:
   - Date dimension pour filtrage temporel
   - Energy type pour segmentation
4. Pour capacitÃ©: charger `fact_renewable_capacity` + `dim_location`
5. CrÃ©er dashboards avec cross-filtering

### Metabase

1. **Settings** â†’ **Admin** â†’ **Databases**
2. **New Database** â†’ **Parquet**
3. Pointer vers `data/warehouse/gold/`
4. Metabase scanne automatiquement les 7 tables
5. CrÃ©er questions avec UI builder, puis dashboards

### DuckDB / Trino / Presto

```sql
-- DuckDB
SELECT * FROM read_parquet('data/warehouse/gold/fact_energy_production/*.parquet') LIMIT 5;
SELECT * FROM read_parquet('data/warehouse/gold/dim_plant/*.parquet') LIMIT 5;

-- Trino
SELECT * FROM hive.default.fact_energy_production;
SELECT * FROM hive.default.dim_plant;

-- RequÃªte multi-table (DuckDB)
SELECT 
    d.region_name,
    SUM(c.total_capacity_mw) as region_capacity
FROM read_parquet('data/warehouse/gold/fact_renewable_capacity/*.parquet') c
JOIN read_parquet('data/warehouse/gold/dim_location/*.parquet') d
    ON c.region = d.region_name
GROUP BY d.region_name
ORDER BY region_capacity DESC;
```

---

## ğŸ› ï¸ Troubleshooting

### âŒ "ModuleNotFoundError: No module named 'pyspark'"

```bash
# Solution: RÃ©installer les dÃ©pendances
pip install -r requirements.txt
```

### âŒ "No such file or directory: 'conf/config.yaml'"

```bash
# Solution: VÃ©rifier que vous Ãªtes dans le bon rÃ©pertoire
cd Spark_dataSpace_Projet
python run.py
```

### âŒ "WinError 5: Access is denied" (lors de l'Ã©criture Parquet)

```bash
# Solution: ExÃ©cuter avec --clean pour nettoyer les fichiers verrouillÃ©s
python run.py --clean
```

### âŒ "DataFrame is highly fragmented" (Warning pandas)

```
âš ï¸ This is a performance warning, not an error
Le pipeline continue et fonctionne correctement
La prochaine version optimisera pd.concat
```

### âŒ "Parquet file not found"

```bash
# Solution: VÃ©rifier que Bronze a Ã©tÃ© exÃ©cutÃ©
python run.py --bronze

# VÃ©rifier les fichiers
ls data/warehouse/bronze/*/data.parquet
```

### ğŸ” DÃ©boguer un job spÃ©cifique

```bash
# ExÃ©cuter directement avec output verbose
.\venv_spark\Scripts\python.exe -u src/jobs/02_silver_clean.py

# Checker les erreurs stderr
python run.py 2>&1 | tee pipeline.log
```

---

## ğŸ“ Licence

Ce projet est fourni Ã  titre Ã©ducatif et professionnel.  
Les donnÃ©es sources proviennent de :
- **RTE** (france_time_series.csv)
- **Eurostat** (eurostat_electricity_france.csv)
- **Open Data RÃ©seaux Ã‰nergies** (renewable_power_plants_FR.csv)

---

## ğŸ¤ Contribution

Pour contribuer :

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

---

## ğŸ“ Support

Pour toute question ou problÃ¨me :

1. VÃ©rifier les logs : `pipeline.log`
2. Consulter la section [Troubleshooting](#ï¸-troubleshooting)
3. VÃ©rifier la configuration : `conf/config.yaml`
4. Relancer avec `--clean` : `python run.py --clean`

---

## ğŸ“… Roadmap

### Phase 1 âœ…
- [x] Bronze layer (ingestion)
- [x] Silver layer (nettoyage)
- [x] Gold layer (star schema)
- [x] Orchestrateur

### Phase 2 (Ã€ venir)
- [ ] Airflow DAG pour scheduling
- [ ] Tests unitaires et d'intÃ©gration
- [ ] Monitoring et alertes
- [ ] Incremental loading

### Phase 3 (Futur)
- [ ] Real-time streaming
- [ ] dbt integration
- [ ] ML pipeline (forecasting)

---

**Made with â¤ï¸ for Energy Data in France**

*DerniÃ¨re mise Ã  jour: 2026-01-11*
